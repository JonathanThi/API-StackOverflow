{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "Nous allons ici développer un algorithme de Machine Learning destiné à assigner automatiquement plusieurs tags pertinents à une question posée sur le célébre site Stack overflow.     \n",
    "Ce programme s'adresse principalement aux nouveaux utilisateurs, afin de leur suggérer quelques tags relatifs à la question qu'ils souhaitent poser.\n",
    "\n",
    "### Les données sources\n",
    "Les données ont été cleanées. Dans ce nettoyage ont par exemple été appliquées les techniques de stop words, suppression de la ponctuation et des liens, tokenisation, lemmatisation ...\n",
    "\n",
    "### Objectif de ce Notebook\n",
    "Dans ce Notebook, nous allons traiter la partie modélisation des données textuelles avec des modèles supervisés et non supervisés.     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T12:49:18.007409Z",
     "iopub.status.busy": "2021-07-12T12:49:18.007081Z",
     "iopub.status.idle": "2021-07-12T12:49:28.985045Z",
     "shell.execute_reply": "2021-07-12T12:49:28.984016Z",
     "shell.execute_reply.started": "2021-07-12T12:49:18.007378Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pycodestyle in c:\\users\\jonat\\anaconda3\\lib\\site-packages (2.6.0)\n",
      "Looking in indexes: https://test.pypi.org/simple/\n",
      "Requirement already satisfied: nbpep8 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (0.0.15)\n"
     ]
    }
   ],
   "source": [
    "# Install package for PEP8 verification\n",
    "!pip install pycodestyle\n",
    "!pip install --index-url https://test.pypi.org/simple/ nbpep8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\jonat\\anaconda3\\lib\\site-packages (4.1.2)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\jonat\\appdata\\roaming\\python\\python38\\site-packages (from gensim) (1.21.4)\n",
      "Requirement already satisfied: Cython==0.29.23 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from gensim) (0.29.23)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from gensim) (1.5.2)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from gensim) (5.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-07-12T12:49:28.98734Z",
     "iopub.status.busy": "2021-07-12T12:49:28.987043Z",
     "iopub.status.idle": "2021-07-12T12:49:28.996967Z",
     "shell.execute_reply": "2021-07-12T12:49:28.995803Z",
     "shell.execute_reply.started": "2021-07-12T12:49:28.987309Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jonat\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:585: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  np.object,\n",
      "C:\\Users\\jonat\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:627: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  np.object,\n",
      "C:\\Users\\jonat\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:637: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  np.bool,\n",
      "C:\\Users\\jonat\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py:176: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  np.object: SlowAppendObjectArrayToTensorProto,\n",
      "C:\\Users\\jonat\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py:177: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  np.bool: SlowAppendBoolArrayToTensorProto,\n",
      "C:\\Users\\jonat\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\numpy_ops\\np_random.py:110: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  def randint(low, high=None, size=None, dtype=onp.int):  # pylint: disable=missing-function-docstring\n"
     ]
    }
   ],
   "source": [
    "# Import Python libraries\n",
    "import os\n",
    "import warnings\n",
    "import time\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import set_config\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "#RNN\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.backend import clear_session\n",
    "from keras import backend as K\n",
    "\n",
    "# Library for PEP8 standard\n",
    "from nbpep8.nbpep8 import pep8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T12:49:28.99937Z",
     "iopub.status.busy": "2021-07-12T12:49:28.998992Z",
     "iopub.status.idle": "2021-07-12T12:49:29.009086Z",
     "shell.execute_reply": "2021-07-12T12:49:29.008346Z",
     "shell.execute_reply.started": "2021-07-12T12:49:28.999323Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jonat\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "sns.set_style(\"whitegrid\")\n",
    "set_config(display='diagram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T12:49:29.011471Z",
     "iopub.status.busy": "2021-07-12T12:49:29.010746Z",
     "iopub.status.idle": "2021-07-12T12:49:34.704155Z",
     "shell.execute_reply": "2021-07-12T12:49:34.703373Z",
     "shell.execute_reply.started": "2021-07-12T12:49:29.011431Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>Score</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>[aspnet, site, map]</td>\n",
       "      <td>[experience, sql, site, map, provider, default...</td>\n",
       "      <td>21</td>\n",
       "      <td>[sql, asp.net]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>[function, color, wheel]</td>\n",
       "      <td>[pseudo, time, solution, problem, way, color, ...</td>\n",
       "      <td>53</td>\n",
       "      <td>[algorithm]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>[scripting, functionality, net, application]</td>\n",
       "      <td>[game, database, end, trading, card, game, fun...</td>\n",
       "      <td>49</td>\n",
       "      <td>[c#, .net]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Title  \\\n",
       "Id                                                  \n",
       "120                           [aspnet, site, map]   \n",
       "180                      [function, color, wheel]   \n",
       "260  [scripting, functionality, net, application]   \n",
       "\n",
       "                                                  Body  Score            Tags  \n",
       "Id                                                                             \n",
       "120  [experience, sql, site, map, provider, default...     21  [sql, asp.net]  \n",
       "180  [pseudo, time, solution, problem, way, color, ...     53     [algorithm]  \n",
       "260  [game, database, end, trading, card, game, fun...     49      [c#, .net]  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"StackOverflow_questions_2009_2020_cleaned.csv\", sep=\";\", index_col=0,\n",
    "                   converters={\"Title\": literal_eval,\n",
    "                               \"Body\": literal_eval,\n",
    "                               \"Tags\": literal_eval}) \n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T12:49:34.707099Z",
     "iopub.status.busy": "2021-07-12T12:49:34.706843Z",
     "iopub.status.idle": "2021-07-12T12:49:34.712859Z",
     "shell.execute_reply": "2021-07-12T12:49:34.711855Z",
     "shell.execute_reply.started": "2021-07-12T12:49:34.707072Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49603, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons également créer une variable 'Full_doc' qui accueillera le document complet de chaque item (Title et Body) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T12:49:34.714319Z",
     "iopub.status.busy": "2021-07-12T12:49:34.714069Z",
     "iopub.status.idle": "2021-07-12T12:49:34.84558Z",
     "shell.execute_reply": "2021-07-12T12:49:34.844741Z",
     "shell.execute_reply.started": "2021-07-12T12:49:34.714294Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id\n",
       "120    [aspnet, site, map, experience, sql, site, map...\n",
       "180    [function, color, wheel, pseudo, time, solutio...\n",
       "260    [scripting, functionality, net, application, g...\n",
       "Name: Full_doc, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Full_doc\"] = data[\"Title\"] + data[\"Body\"]\n",
    "data[\"Full_doc\"].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>Score</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Full_doc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>[aspnet, site, map]</td>\n",
       "      <td>[experience, sql, site, map, provider, default...</td>\n",
       "      <td>21</td>\n",
       "      <td>[sql, asp.net]</td>\n",
       "      <td>[aspnet, site, map, experience, sql, site, map...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>[function, color, wheel]</td>\n",
       "      <td>[pseudo, time, solution, problem, way, color, ...</td>\n",
       "      <td>53</td>\n",
       "      <td>[algorithm]</td>\n",
       "      <td>[function, color, wheel, pseudo, time, solutio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>[scripting, functionality, net, application]</td>\n",
       "      <td>[game, database, end, trading, card, game, fun...</td>\n",
       "      <td>49</td>\n",
       "      <td>[c#, .net]</td>\n",
       "      <td>[scripting, functionality, net, application, g...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Title  \\\n",
       "Id                                                  \n",
       "120                           [aspnet, site, map]   \n",
       "180                      [function, color, wheel]   \n",
       "260  [scripting, functionality, net, application]   \n",
       "\n",
       "                                                  Body  Score            Tags  \\\n",
       "Id                                                                              \n",
       "120  [experience, sql, site, map, provider, default...     21  [sql, asp.net]   \n",
       "180  [pseudo, time, solution, problem, way, color, ...     53     [algorithm]   \n",
       "260  [game, database, end, trading, card, game, fun...     49      [c#, .net]   \n",
       "\n",
       "                                              Full_doc  \n",
       "Id                                                      \n",
       "120  [aspnet, site, map, experience, sql, site, map...  \n",
       "180  [function, color, wheel, pseudo, time, solutio...  \n",
       "260  [scripting, functionality, net, application, g...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_tfidf (x):\n",
    "    \n",
    "    txt = \" \".join(x)\n",
    "    #txt = txt.replace('[', '')\n",
    "    #txt = txt.replace(']', '')\n",
    "    #txt = txt.replace(',', '')\n",
    "    \n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Full_doc'] = data['Full_doc'].apply(remove_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>Score</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Full_doc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>[aspnet, site, map]</td>\n",
       "      <td>[experience, sql, site, map, provider, default...</td>\n",
       "      <td>21</td>\n",
       "      <td>[sql, asp.net]</td>\n",
       "      <td>aspnet site map experience sql site map provid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>[function, color, wheel]</td>\n",
       "      <td>[pseudo, time, solution, problem, way, color, ...</td>\n",
       "      <td>53</td>\n",
       "      <td>[algorithm]</td>\n",
       "      <td>function color wheel pseudo time solution prob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>[scripting, functionality, net, application]</td>\n",
       "      <td>[game, database, end, trading, card, game, fun...</td>\n",
       "      <td>49</td>\n",
       "      <td>[c#, .net]</td>\n",
       "      <td>scripting functionality net application game d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Title  \\\n",
       "Id                                                  \n",
       "120                           [aspnet, site, map]   \n",
       "180                      [function, color, wheel]   \n",
       "260  [scripting, functionality, net, application]   \n",
       "\n",
       "                                                  Body  Score            Tags  \\\n",
       "Id                                                                              \n",
       "120  [experience, sql, site, map, provider, default...     21  [sql, asp.net]   \n",
       "180  [pseudo, time, solution, problem, way, color, ...     53     [algorithm]   \n",
       "260  [game, database, end, trading, card, game, fun...     49      [c#, .net]   \n",
       "\n",
       "                                              Full_doc  \n",
       "Id                                                      \n",
       "120  aspnet site map experience sql site map provid...  \n",
       "180  function color wheel pseudo time solution prob...  \n",
       "260  scripting functionality net application game d...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing : Bag of Words / Tf-Idf\n",
    "\n",
    "Pour alimenter les modèles de machine learning, nous avons besoin de traiter des données numériques. Le modèle Bag of Words apprend un vocabulaire à partir de tous les documents, puis modélise chaque document en comptant le nombre de fois où chaque mot apparaît, convertissant donc les données textuelles en données numériques.\n",
    "\n",
    "Nos données ayant déjà été cleanées et tokenisées, nous allons initialiser l'algorithme du CountVectorizer sur les variables Title et Body (X1 et X2) sans preprocessing. Enfin, nous allons utiliser le module TfidfVectorizer de la librairie Scikit-Learn pour combiner le CountVectorizer et TfidfTransformer. Cela aura pour effet de pondérer la fréquence d'apparition des mots par un indicateur de similarité (si ce mot est commun ou rare dans tous les documents). Dans cette partie, nous allons éliminer les mots qui apparaissent dans plus de 75% des documents (max_df = 0.75) ainsi que ceux qui apparaissent dans moins de 5% (min_df = 0.05).\n",
    "\n",
    "La métrique tf-idf (Term-Frequency - Inverse Document Frequency) utilise comme indicateur de similarité l'Inverse Document Frequency,  qui est l'inverse de la proportion de document qui contient le terme, à l'échelle logarithmique.\n",
    "\n",
    "Pour préparer nos targets (pour les modèles supervisés), nous allons utiliser MultiLabelBinarizer de Scikit-Learn puisque nos Tags sont multiples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf(data):\n",
    "    \n",
    "    tfidf_vec = TfidfVectorizer()\n",
    "    \n",
    "    #tfidf_model = tfidf_vec.fit(data)\n",
    "    \n",
    "    #print(tfidf_model.dtype)\n",
    "    \n",
    "    #X_tfidf = tfidf_model.transform(data)\n",
    "    \n",
    "    X_tfidf = tfidf_vec.fit_transform(data)\n",
    "    #X_feature = tfidf_vec.get_feature_names()\n",
    "    return X_tfidf\n",
    "\n",
    "def tfid2(data):\n",
    "    \n",
    "    vectorizer = CountVectorizer() # This class will transform the words in the text into a word frequency matrix, and the matrix element a[i][j] represents the word frequency of word j under class i text\n",
    "    transformer = TfidfTransformer() # This class will count the tf-idf weights of each word\n",
    "    tfidf_before = vectorizer.fit_transform(data)\n",
    "    tfidf = transformer.fit_transform(tfidf_before)\n",
    "    \n",
    "    return tfidf\n",
    "\n",
    "def tfidf3(X_train,X_test):\n",
    "    \n",
    "    tfidf_vec = TfidfVectorizer(analyzer=\"word\",\n",
    "                                max_df=0.75,\n",
    "                                min_df=0.05,\n",
    "                                tokenizer=None,\n",
    "                                preprocessor=' '.join,\n",
    "                                stop_words=None,\n",
    "                                lowercase=False)\n",
    "    \n",
    "    X_train_tfidf = tfidf_vec.fit_transform(X_train)\n",
    "    X_test_tfidf = tfidf_vec.transform(X_test)\n",
    "    \n",
    "    return X_train_tfidf,X_test_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X and y\n",
    "X = data[\"Full_doc\"]\n",
    "y = data[\"Tags\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>[sql, asp.net]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>[algorithm]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>[c#, .net]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>[c++]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>[.net]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Tags\n",
       "Id                 \n",
       "120  [sql, asp.net]\n",
       "180     [algorithm]\n",
       "260      [c#, .net]\n",
       "330           [c++]\n",
       "470          [.net]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df = pd.DataFrame(y)\n",
    "X_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>[sql, asp.net]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>[algorithm]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>[c#, .net]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>[c++]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>[.net]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Tags\n",
       "Id                 \n",
       "120  [sql, asp.net]\n",
       "180     [algorithm]\n",
       "260      [c#, .net]\n",
       "330           [c++]\n",
       "470          [.net]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_df = pd.DataFrame(y)\n",
    "y_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id\n",
       "120    aspnet site map experience sql site map provid...\n",
       "180    function color wheel pseudo time solution prob...\n",
       "260    scripting functionality net application game d...\n",
       "Name: Full_doc, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X for Full_doc: (49603, 47003)\n",
      "Shape of y: (49603, 50)\n"
     ]
    }
   ],
   "source": [
    "X_tfidf = tfidf(X)\n",
    "\n",
    "print(\"Shape of X for Full_doc: {}\".format(X_tfidf.shape))\n",
    "\n",
    "# Multilabel binarizer for targets\n",
    "multilabel_binarizer = MultiLabelBinarizer()\n",
    "multilabel_binarizer.fit(y)\n",
    "y_binarized = multilabel_binarizer.transform(y)\n",
    "\n",
    "print(\"Shape of y: {}\".format(y_binarized.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On réduit maintenant les dimension à l'aide de SVD.\n",
    "On souhaite conserver 95% de la variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "def select_n_components(var_ratio, goal_var: float) -> int:\n",
    "    # Set initial variance explained so far\n",
    "    total_variance = 0.0\n",
    "    \n",
    "    # Set initial number of features\n",
    "    n_components = 0\n",
    "    \n",
    "    # For the explained variance of each feature:\n",
    "    for explained_variance in var_ratio:\n",
    "        \n",
    "        # Add the explained variance to the total\n",
    "        total_variance += explained_variance\n",
    "        \n",
    "        # Add one to the number of components\n",
    "        n_components += 1\n",
    "        \n",
    "        # If we reach our goal level of explained variance\n",
    "        if total_variance >= goal_var:\n",
    "            # End the loop\n",
    "            break\n",
    "            \n",
    "    # Return the number of components\n",
    "    return n_components"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "svd = TruncatedSVD(n_components=X_tfidf.shape[1]-1) # Defining TruncatedSVD Object\n",
    "svd.fit_transform(X_tfidf); # Calling fit_transform method on X_train_scaled Dataset\n",
    "\n",
    "svd_var_ratios = svd.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Run function\n",
    "select_n_components(svd_var_ratios, 0.95)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape : (34722, 47003)\n",
      "X_test shape : (14881, 47003)\n",
      "y_train shape : (34722, 50)\n",
      "y_test shape : (14881, 50)\n"
     ]
    }
   ],
   "source": [
    "# Create train and test split (30%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y_binarized, test_size=0.3, random_state=8)\n",
    "print(\"X_train shape : {}\".format(X_train.shape))\n",
    "print(\"X_test shape : {}\".format(X_test.shape))\n",
    "print(\"y_train shape : {}\".format(y_train.shape))\n",
    "print(\"y_test shape : {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "\n",
    "svd.fit(sp.sparse.vstack((X_train, X_test)))\n",
    "X_train = svd.transform(X_train)\n",
    "X_test = svd.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modèles non supervisés\n",
    "\n",
    "## Modèle LDA\n",
    "LDA, ou Latent Dirichlet Allocation est un modèle probabiliste qui, pour obtenir des affectations de cluster, utilise deux valeurs de probabilité : P(word | topics) et P(topics | documents). Ces valeurs sont calculées sur la base d'une attribution aléatoire initiale, puis le calcul est répété pour chaque mot dans chaque document, pour décider de leur attribution de sujet. Dans cette méthode itérative, ces probabilités sont calculées plusieurs fois, jusqu'à la convergence de l'algorithme.\n",
    "\n",
    "Nous allons entrainer 1 seul modèle basé sur la variable Full_doc en utilisant la librairie spécialisée Gensim. Pour cette partie, nous n'utiliserons pas le preprocessing TFIDF mais des fonctions propres aux méthodes Gensim.\n",
    "\n",
    "Dans une première étape, le Bag of words est créé ainsi que la matrice de fréquence des termes dans les documents :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X and y\n",
    "X = data[\"Full_doc\"]\n",
    "y = data[\"Tags\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T12:49:40.786814Z",
     "iopub.status.busy": "2021-07-12T12:49:40.786451Z",
     "iopub.status.idle": "2021-07-12T12:49:46.403002Z",
     "shell.execute_reply": "2021-07-12T12:49:46.402083Z",
     "shell.execute_reply.started": "2021-07-12T12:49:40.786777Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create dictionnary (bag of words)\n",
    "id2word = corpora.Dictionary(X)\n",
    "id2word.filter_extremes(no_below=4, no_above=0.75, keep_n=None)\n",
    "# Create Corpus \n",
    "texts = X  \n",
    "# Term Document Frequency \n",
    "corpus = [id2word.doc2bow(text) for text in texts]  \n",
    "# View \n",
    "print(corpus[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gensim crée un identifiant unique pour chaque mot du document puis mappe word_id et word_frequency. Exemple : (6,3) ci-dessus indique que word_id 6 apparaît 3 fois dans le document et ainsi de suite.      \n",
    "Les mots les plus fréquents ont ici aussi été filtrés grâce à la fonction filter_extremes réglée à 75% comme pour le Tfidf.\n",
    "\n",
    "Pour voir quel mot correspond à un identifiant donné, il faut transmettre l'identifiant comme clé du dictionnaire. Exemple : id2word[4] :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T12:49:46.404281Z",
     "iopub.status.busy": "2021-07-12T12:49:46.404036Z",
     "iopub.status.idle": "2021-07-12T12:49:46.413645Z",
     "shell.execute_reply": "2021-07-12T12:49:46.412763Z",
     "shell.execute_reply.started": "2021-07-12T12:49:46.404257Z"
    }
   },
   "outputs": [],
   "source": [
    "[[(id2word[id], freq) for id, freq in cp] for cp in corpus[:1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons à présent entrainer le modèle LDA sur Full_doc puis afficher les métriques : \n",
    "- Perplexity :  Log likelihood - Densité de vraisemblance\n",
    "- Coherence Score : Les mesures de cohérence de topics évaluent un seul topic en mesurant le degré de similitude sémantique entre les mots à score élevé dans ce dernier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T12:49:46.415012Z",
     "iopub.status.busy": "2021-07-12T12:49:46.414716Z",
     "iopub.status.idle": "2021-07-12T12:51:33.414986Z",
     "shell.execute_reply": "2021-07-12T12:51:33.414007Z",
     "shell.execute_reply.started": "2021-07-12T12:49:46.414977Z"
    }
   },
   "outputs": [],
   "source": [
    "# Build LDA model\n",
    "full_lda_model = gensim.models.ldamulticore\\\n",
    "                    .LdaMulticore(corpus=corpus,\n",
    "                                  id2word=id2word,\n",
    "                                  num_topics=20,\n",
    "                                  random_state=8,\n",
    "                                  per_word_topics=True,\n",
    "                                  workers=4)\n",
    "# Print Perplexity score\n",
    "print('\\nPerplexity: ', full_lda_model.log_perplexity(corpus))\n",
    "\n",
    "#Print Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=full_lda_model, \n",
    "                                     texts=texts, \n",
    "                                     dictionary=id2word, \n",
    "                                     coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation des résultats de LDA Gensim sur Full_doc avec 20 topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D'après les résultats de cette modélisation LDA, il semble très difficile de \"nommer\" les topics créés car les mots qui les composent sont très variés et sans fil conducteur clairement établi. On voit cependant par exemple que le topic représenté par \"server\" englobe également \"database\", \"sql\", \"connection\" ou encore \"query\" ce qui est cohérent.\n",
    "\n",
    "### Amélioration du modèle LDA\n",
    "\n",
    "Cependant, dans l'algoritme LDA, nous avons fixé arbitrairement à 20 le paramètre num_topics, qui représente le nombre de topics à créer. \n",
    "Afin de sélectionner le meilleur nombre de topics pour nos données, nous allons itérer sur un intervalle de nombre de topics et tester le score de cohérence pour chaque modèle :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T12:51:33.416528Z",
     "iopub.status.busy": "2021-07-12T12:51:33.416267Z",
     "iopub.status.idle": "2021-07-12T12:52:20.573381Z",
     "shell.execute_reply": "2021-07-12T12:52:20.572494Z",
     "shell.execute_reply.started": "2021-07-12T12:51:33.416491Z"
    }
   },
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "%matplotlib inline\n",
    "\n",
    "display(HTML(\"<style>.container { max-width:100% !important; }</style>\"))\n",
    "display(HTML(\"<style>.output_result { max-width:100% !important; }</style>\"))\n",
    "display(HTML(\"<style>.output_area { max-width:100% !important; }</style>\"))\n",
    "display(HTML(\"<style>.input_area { max-width:100% !important; }</style>\"))\n",
    "\n",
    "gensimvis.prepare(full_lda_model, corpus, id2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T12:52:20.575532Z",
     "iopub.status.busy": "2021-07-12T12:52:20.575086Z",
     "iopub.status.idle": "2021-07-12T13:01:08.260441Z",
     "shell.execute_reply": "2021-07-12T13:01:08.259408Z",
     "shell.execute_reply.started": "2021-07-12T12:52:20.575488Z"
    }
   },
   "outputs": [],
   "source": [
    "# Iter LDA for best number of topics\n",
    "coherence_test = []\n",
    "for k in np.arange(1,90,10):\n",
    "    print(\"Fitting LDA for K = {}\".format(k))\n",
    "    start_time = time.time()\n",
    "    lda_model = gensim.models.ldamulticore\\\n",
    "                    .LdaMulticore(corpus=corpus,\n",
    "                                  id2word=id2word,\n",
    "                                  num_topics=k,\n",
    "                                  random_state=8,\n",
    "                                  per_word_topics=True,\n",
    "                                  workers=4)\n",
    "    coherence_model_lda = CoherenceModel(model=lda_model,\n",
    "                                         texts=texts,\n",
    "                                         dictionary=id2word,\n",
    "                                         coherence='c_v')\n",
    "    coherence_lda = coherence_model_lda.get_coherence()\n",
    "    end_time = time.time()\n",
    "    coherence_test.append((k, coherence_lda,\n",
    "                           (end_time - start_time)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichons les scores des divers modèles :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T13:01:08.262575Z",
     "iopub.status.busy": "2021-07-12T13:01:08.262175Z",
     "iopub.status.idle": "2021-07-12T13:01:08.751563Z",
     "shell.execute_reply": "2021-07-12T13:01:08.749431Z",
     "shell.execute_reply.started": "2021-07-12T13:01:08.262529Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create dataframe of results\n",
    "coherence_test = pd.DataFrame(coherence_test,\n",
    "                              columns=[\"k\",\"coherence\",\"time\"])\n",
    "\n",
    "# Select best number of topics\n",
    "best_nb_topics = coherence_test\\\n",
    "                    .loc[coherence_test.coherence.argmax(),\"k\"]\n",
    "\n",
    "# Plot results\n",
    "fig, ax1 = plt.subplots(figsize=(12,8))\n",
    "x = coherence_test[\"k\"]\n",
    "y1 = coherence_test[\"coherence\"]\n",
    "y2 = coherence_test[\"time\"]\n",
    "\n",
    "ax1.plot(x, y1, label=\"Coherence score\")\n",
    "ax1.axvline(x=best_nb_topics, color='r', alpha=.7,\n",
    "            linestyle='dashdot', label='Best param')\n",
    "ax1.set_xlabel(\"Number of components\")\n",
    "ax1.set_ylabel(\"Coherence score\")\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(x, y2, label=\"Fit time\",\n",
    "         color='g', alpha=.5,\n",
    "         linestyle='--')\n",
    "ax2.set_ylabel(\"Fitting time (s)\")\n",
    "\n",
    "plt.title(\"Modèle LDA Optimal \\n\",\n",
    "          color=\"#641E16\", fontsize=18)\n",
    "legend = fig.legend(loc=1, bbox_to_anchor=(.92, .9))\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_nb_topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testons à présent le modèle avec le meilleur nombre théorique de topics pour l'afficher avec LDAvis :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T13:01:08.752878Z",
     "iopub.status.busy": "2021-07-12T13:01:08.752598Z",
     "iopub.status.idle": "2021-07-12T13:02:26.557238Z",
     "shell.execute_reply": "2021-07-12T13:02:26.556497Z",
     "shell.execute_reply.started": "2021-07-12T13:01:08.752853Z"
    }
   },
   "outputs": [],
   "source": [
    "# Best LDA visualization\n",
    "# Construire le modèle LDA\n",
    "best_lda_model = gensim.models.ldamulticore\\\n",
    "                    .LdaMulticore(corpus=corpus,\n",
    "                                  id2word=id2word,\n",
    "                                  num_topics=best_nb_topics,\n",
    "                                  random_state=8,\n",
    "                                  per_word_topics=True,\n",
    "                                  workers=4)\n",
    "gensimvis.prepare(best_lda_model, corpus, id2word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour attribuer des Tags à chaque question sur ces modèles non-supervisés, nous allons créer une matrice Topic/Tags en réalisant une multiplication matricielle des matrices Document / Topic et Document / Tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T13:02:26.558913Z",
     "iopub.status.busy": "2021-07-12T13:02:26.558484Z",
     "iopub.status.idle": "2021-07-12T13:03:27.189379Z",
     "shell.execute_reply": "2021-07-12T13:03:27.18866Z",
     "shell.execute_reply.started": "2021-07-12T13:02:26.558876Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate Document/topic matrix with Gensim\n",
    "doc_topic = pd.DataFrame(best_lda_model\\\n",
    "                             .get_document_topics(corpus,\n",
    "                                                  minimum_probability=0))\n",
    "for topic in doc_topic.columns:\n",
    "    doc_topic[topic] = doc_topic[topic].apply(lambda x : x[1])\n",
    "\n",
    "print('document/tag : ', y_binarized.shape)\n",
    "print('document/topic : ', doc_topic.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T13:03:27.190819Z",
     "iopub.status.busy": "2021-07-12T13:03:27.190483Z",
     "iopub.status.idle": "2021-07-12T13:03:27.217265Z",
     "shell.execute_reply": "2021-07-12T13:03:27.216657Z",
     "shell.execute_reply.started": "2021-07-12T13:03:27.19079Z"
    }
   },
   "outputs": [],
   "source": [
    "# Print documents / topic matrix\n",
    "doc_topic.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A présent, créons la matrice Topic / Tags grâce aux probabilités obtenues :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T13:03:27.219237Z",
     "iopub.status.busy": "2021-07-12T13:03:27.218608Z",
     "iopub.status.idle": "2021-07-12T13:03:27.269052Z",
     "shell.execute_reply": "2021-07-12T13:03:27.268012Z",
     "shell.execute_reply.started": "2021-07-12T13:03:27.219197Z"
    }
   },
   "outputs": [],
   "source": [
    "# Matricial multiplication with Document / Topics transpose\n",
    "topic_tag = np.matmul(doc_topic.T, y_binarized)\n",
    "topic_tag.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T13:03:27.271498Z",
     "iopub.status.busy": "2021-07-12T13:03:27.270834Z",
     "iopub.status.idle": "2021-07-12T13:03:27.350437Z",
     "shell.execute_reply": "2021-07-12T13:03:27.349344Z",
     "shell.execute_reply.started": "2021-07-12T13:03:27.271453Z"
    }
   },
   "outputs": [],
   "source": [
    "topic_tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous obtenons donc une matrice dont les lignes représentent les Topics créés et les colonnes les Tags associés et leurs distribution. Nous allons donc créer nos prédictions en prenant les n premiers tags associés aux topics de chaque document :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T13:03:27.352804Z",
     "iopub.status.busy": "2021-07-12T13:03:27.352081Z",
     "iopub.status.idle": "2021-07-12T13:04:36.764381Z",
     "shell.execute_reply": "2021-07-12T13:04:36.763719Z",
     "shell.execute_reply.started": "2021-07-12T13:03:27.352755Z"
    }
   },
   "outputs": [],
   "source": [
    "y_results = pd.DataFrame(y)\n",
    "y_results[\"best_topic\"] = doc_topic.idxmax(axis=1).values\n",
    "y_results[\"nb_tags\"] = y_results[\"Tags\"].apply(lambda x : len(x))\n",
    "\n",
    "df_y_bin = pd.DataFrame(y_binarized)\n",
    "df_dict = dict(\n",
    "    list(\n",
    "        df_y_bin.groupby(df_y_bin.index)\n",
    "    )\n",
    ")\n",
    "\n",
    "tags_num = []\n",
    "for k, v in df_dict.items():\n",
    "    check = v.columns[(v == 1).any()]\n",
    "    tags_num.append(check.to_list())\n",
    "\n",
    "y_results[\"y_true\"] = tags_num\n",
    "y_results.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T13:04:36.766034Z",
     "iopub.status.busy": "2021-07-12T13:04:36.765506Z",
     "iopub.status.idle": "2021-07-12T13:04:55.70805Z",
     "shell.execute_reply": "2021-07-12T13:04:55.707388Z",
     "shell.execute_reply.started": "2021-07-12T13:04:36.766002Z"
    }
   },
   "outputs": [],
   "source": [
    "# Select predicted tags in Topics / Tags matrix\n",
    "list_tag = []\n",
    "for row in y_results.itertuples():\n",
    "    nb_tags = row.nb_tags\n",
    "    best_topic = row.best_topic\n",
    "    row_tags = list(topic_tag.iloc[best_topic]\\\n",
    "                    .sort_values(ascending=False)[0:nb_tags].index)\n",
    "    list_tag.append(row_tags)\n",
    "    \n",
    "y_results[\"y_pred\"] = list_tag\n",
    "y_results.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons tester plusieurs métriques sur ce modèle LDA :\n",
    "- Accuracy score :\n",
    "- F1 score :\n",
    "- Jaccard similarity score : \n",
    "- Recall :\n",
    "- Precision :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T13:04:55.711999Z",
     "iopub.status.busy": "2021-07-12T13:04:55.711567Z",
     "iopub.status.idle": "2021-07-12T13:04:55.719096Z",
     "shell.execute_reply": "2021-07-12T13:04:55.718226Z",
     "shell.execute_reply.started": "2021-07-12T13:04:55.71197Z"
    }
   },
   "outputs": [],
   "source": [
    "def metrics_score(model, df, y_true, y_pred):\n",
    "    \"\"\"Compilation function of metrics specific to multi-label\n",
    "    classification problems in a Pandas DataFrame.\n",
    "    This dataFrame will have 1 row per metric\n",
    "    and 1 column per model tested. \n",
    "\n",
    "    Parameters\n",
    "    ----------------------------------------\n",
    "    model : string\n",
    "        Name of the tested model\n",
    "    df : DataFrame \n",
    "        DataFrame to extend. \n",
    "        If None : Create DataFrame.\n",
    "    y_true : array\n",
    "        Array of true values to test\n",
    "    y_pred : array\n",
    "        Array of predicted values to test\n",
    "    ----------------------------------------\n",
    "    \"\"\"\n",
    "    if(df is not None):\n",
    "        temp_df = df\n",
    "    else:\n",
    "        temp_df = pd.DataFrame(index=[\"Accuracy\", \"F1\",\n",
    "                                      \"Jaccard\", \"Recall\",\n",
    "                                      \"Precision\"],\n",
    "                               columns=[model])\n",
    "        \n",
    "    scores = []\n",
    "    scores.append(metrics.accuracy_score(y_true, \n",
    "                                         y_pred))\n",
    "    scores.append(metrics.f1_score(y_pred, \n",
    "                                   y_true, \n",
    "                                   average='weighted'))\n",
    "    scores.append(metrics.jaccard_score(y_true, \n",
    "                                        y_pred, \n",
    "                                        average='weighted'))\n",
    "    scores.append(metrics.recall_score(y_true, \n",
    "                                       y_pred, \n",
    "                                       average='weighted'))\n",
    "    scores.append(metrics.precision_score(y_true, \n",
    "                                          y_pred, \n",
    "                                          average='weighted'))\n",
    "    temp_df[model] = scores\n",
    "    \n",
    "    return temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T13:04:55.720899Z",
     "iopub.status.busy": "2021-07-12T13:04:55.720674Z",
     "iopub.status.idle": "2021-07-12T13:04:55.945154Z",
     "shell.execute_reply": "2021-07-12T13:04:55.944308Z",
     "shell.execute_reply.started": "2021-07-12T13:04:55.720877Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create matrix for pred and true y LDA\n",
    "lda_y_pred = np.zeros(y_binarized.shape)\n",
    "n = 0\n",
    "for row in y_results.y_pred.values:\n",
    "    for i in range(len(row)):\n",
    "        lda_y_pred[n,row[i]] = 1\n",
    "    n+=1\n",
    "    \n",
    "lda_y_true = np.zeros(y_binarized.shape)\n",
    "m = 0\n",
    "for row in y_results.y_true.values:\n",
    "    for i in range(len(row)):\n",
    "        lda_y_true[m,row[i]] = 1\n",
    "    m+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T13:04:55.946987Z",
     "iopub.status.busy": "2021-07-12T13:04:55.946574Z",
     "iopub.status.idle": "2021-07-12T13:04:58.477333Z",
     "shell.execute_reply": "2021-07-12T13:04:58.476426Z",
     "shell.execute_reply.started": "2021-07-12T13:04:55.946947Z"
    }
   },
   "outputs": [],
   "source": [
    "df_metrics_compare = metrics_score(\"LDA\", df=None,\n",
    "                                   y_true=lda_y_true,\n",
    "                                   y_pred=lda_y_pred)\n",
    "df_metrics_compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque ici que la modélisation non supervisée avec LDA n'est pas adaptée. En effet, le meilleur nombre de topics se situerait à 21, mais l'algorithme ne parvient pas a établir de groupes bien distincts. Un certain nombre de topics sont très regroupés et donc représentés par les mêmes termes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modèles supervisés\n",
    "\n",
    "## Régression logistique avec multi-labels\n",
    "\n",
    "Cette technique vise à construire un modèle permettant de prédire / expliquer les valeurs prises par une variable cible qualitative à partir d’un ensemble de variables explicatives quantitatives ou qualitatives encodées.\n",
    "\n",
    "Pour cette partie sur les modélisations supervisées, nous allons utiliser la variable Full_doc qui regroupe le Title et le Body puis créer un Pipeline qui ne pourra pas inclure la transformation de notre variable cible (MultiLabelBinarizer ne fonctionne pas dans les Pipeline SKlearn)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T13:05:29.114004Z",
     "iopub.status.busy": "2021-07-12T13:05:29.113509Z",
     "iopub.status.idle": "2021-07-12T13:10:55.426661Z",
     "shell.execute_reply": "2021-07-12T13:10:55.425787Z",
     "shell.execute_reply.started": "2021-07-12T13:05:29.113968Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize Logistic Regression with OneVsRest\n",
    "param_logit = {\"estimator__C\": [100, 10, 1.0, 0.1],\n",
    "               \"estimator__penalty\": [\"l1\", \"l2\"],\n",
    "               \"estimator__dual\": [False],\n",
    "               \"estimator__solver\": [\"liblinear\"]}\n",
    "\n",
    "multi_logit_cv = GridSearchCV(OneVsRestClassifier(LogisticRegression()),\n",
    "                              param_grid=param_logit,\n",
    "                              n_jobs=-1,\n",
    "                              cv=5,\n",
    "                              scoring=\"f1_weighted\",\n",
    "                              return_train_score = True,\n",
    "                              refit=True)\n",
    "multi_logit_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T13:10:55.428672Z",
     "iopub.status.busy": "2021-07-12T13:10:55.428252Z",
     "iopub.status.idle": "2021-07-12T13:10:55.437657Z",
     "shell.execute_reply": "2021-07-12T13:10:55.436707Z",
     "shell.execute_reply.started": "2021-07-12T13:10:55.428618Z"
    }
   },
   "outputs": [],
   "source": [
    "logit_cv_results = pd.DataFrame.from_dict(multi_logit_cv.cv_results_)\n",
    "print(\"-\"*50)\n",
    "print(\"Best params for Logistic Regression\")\n",
    "print(\"-\" * 50)\n",
    "logit_best_params = multi_logit_cv.best_params_\n",
    "print(logit_best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T13:10:55.438983Z",
     "iopub.status.busy": "2021-07-12T13:10:55.438684Z",
     "iopub.status.idle": "2021-07-12T13:10:55.468957Z",
     "shell.execute_reply": "2021-07-12T13:10:55.467931Z",
     "shell.execute_reply.started": "2021-07-12T13:10:55.438952Z"
    }
   },
   "outputs": [],
   "source": [
    "logit_cv_results[logit_cv_results[\"params\"]==logit_best_params]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons maintenant réaliser les prédictions avec le modèle de régression logistique sur le jeu de test pour pouvoir les comparer avec le jeu y_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T13:10:55.470321Z",
     "iopub.status.busy": "2021-07-12T13:10:55.470019Z",
     "iopub.status.idle": "2021-07-12T13:10:55.712833Z",
     "shell.execute_reply": "2021-07-12T13:10:55.711844Z",
     "shell.execute_reply.started": "2021-07-12T13:10:55.470295Z"
    }
   },
   "outputs": [],
   "source": [
    "# Predict\n",
    "y_test_predicted_labels_tfidf = multi_logit_cv.predict(X_test)\n",
    "\n",
    "# Inverse transform\n",
    "y_test_pred_inversed = multilabel_binarizer\\\n",
    "    .inverse_transform(y_test_predicted_labels_tfidf)\n",
    "y_test_inversed = multilabel_binarizer\\\n",
    "    .inverse_transform(y_test)\n",
    "\n",
    "print(\"-\"*50)\n",
    "print(\"Print 5 first predicted Tags vs true Tags\")\n",
    "print(\"-\" * 50)\n",
    "print(\"Predicted:\", y_test_pred_inversed[0:5])\n",
    "print(\"True:\", y_test_inversed[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puis nous calculons les diverses métriques sur le meilleur modèle de régression logistique :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T13:10:55.714301Z",
     "iopub.status.busy": "2021-07-12T13:10:55.714038Z",
     "iopub.status.idle": "2021-07-12T13:10:56.313065Z",
     "shell.execute_reply": "2021-07-12T13:10:56.312142Z",
     "shell.execute_reply.started": "2021-07-12T13:10:55.714273Z"
    }
   },
   "outputs": [],
   "source": [
    "df_metrics_compare = metrics_score(\"Logit\", \n",
    "                                   df=df_metrics_compare, \n",
    "                                   y_true = y_test,\n",
    "                                   y_pred = y_test_predicted_labels_tfidf)\n",
    "df_metrics_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span id=\"section_3_2\">Modélisation avec RandomForest</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T13:10:56.316124Z",
     "iopub.status.busy": "2021-07-12T13:10:56.315847Z",
     "iopub.status.idle": "2021-07-12T13:14:16.859153Z",
     "shell.execute_reply": "2021-07-12T13:14:16.858281Z",
     "shell.execute_reply.started": "2021-07-12T13:10:56.3161Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize RandomForest with OneVsRest\n",
    "param_rfc = {\"estimator__max_depth\": [5, 25, 50],\n",
    "             \"estimator__min_samples_leaf\": [1, 5, 10],\n",
    "             \"estimator__class_weight\": [\"balanced\"]}\n",
    "\n",
    "multi_rfc_cv = GridSearchCV(OneVsRestClassifier(RandomForestClassifier()),\n",
    "                            param_grid=param_rfc,\n",
    "                            n_jobs=-1,\n",
    "                            cv=2,\n",
    "                            scoring=\"f1_weighted\",\n",
    "                            return_train_score = True,\n",
    "                            refit=True,\n",
    "                            verbose=3)\n",
    "# Fit on Sample data\n",
    "multi_rfc_cv.fit(X_train[0:7000], y_train[0:7000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T13:14:16.860583Z",
     "iopub.status.busy": "2021-07-12T13:14:16.860332Z",
     "iopub.status.idle": "2021-07-12T13:14:16.867919Z",
     "shell.execute_reply": "2021-07-12T13:14:16.86733Z",
     "shell.execute_reply.started": "2021-07-12T13:14:16.860557Z"
    }
   },
   "outputs": [],
   "source": [
    "rfc_cv_results = pd.DataFrame.from_dict(multi_rfc_cv.cv_results_)\n",
    "print(\"-\"*50)\n",
    "print(\"Best params for RandomForestClassifier\")\n",
    "print(\"-\" * 50)\n",
    "rfc_best_params = multi_rfc_cv.best_params_\n",
    "print(rfc_best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T13:14:16.869201Z",
     "iopub.status.busy": "2021-07-12T13:14:16.868821Z",
     "iopub.status.idle": "2021-07-12T13:14:16.87914Z",
     "shell.execute_reply": "2021-07-12T13:14:16.87845Z",
     "shell.execute_reply.started": "2021-07-12T13:14:16.869174Z"
    }
   },
   "outputs": [],
   "source": [
    "rfc_best_params_ok = {}\n",
    "for k, v in rfc_best_params.items():\n",
    "    rfc_best_params_ok[k.replace(\"estimator__\",\"\")] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T13:14:16.880368Z",
     "iopub.status.busy": "2021-07-12T13:14:16.879987Z",
     "iopub.status.idle": "2021-07-12T13:22:15.200315Z",
     "shell.execute_reply": "2021-07-12T13:22:15.199154Z",
     "shell.execute_reply.started": "2021-07-12T13:14:16.880333Z"
    }
   },
   "outputs": [],
   "source": [
    "# Refit RandomForestClassifier best_params with full dataset\n",
    "rfc_final_model = OneVsRestClassifier(RandomForestClassifier(**rfc_best_params_ok))\n",
    "rfc_final_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_test_predicted_labels_tfidf_rfc = rfc_final_model.predict(X_test)\n",
    "\n",
    "# Inverse transform\n",
    "y_test_pred_inversed_rfc = multilabel_binarizer\\\n",
    "    .inverse_transform(y_test_predicted_labels_tfidf_rfc)\n",
    "\n",
    "print(\"-\"*50)\n",
    "print(\"Print 5 first predicted Tags vs true Tags\")\n",
    "print(\"-\" * 50)\n",
    "print(\"Predicted:\", y_test_pred_inversed_rfc[0:5])\n",
    "print(\"True:\", y_test_inversed[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T13:22:15.202356Z",
     "iopub.status.busy": "2021-07-12T13:22:15.201973Z",
     "iopub.status.idle": "2021-07-12T13:22:15.781384Z",
     "shell.execute_reply": "2021-07-12T13:22:15.780622Z",
     "shell.execute_reply.started": "2021-07-12T13:22:15.202316Z"
    }
   },
   "outputs": [],
   "source": [
    "df_metrics_compare = metrics_score(\"RandomForest\", \n",
    "                                   df=df_metrics_compare,\n",
    "                                   y_true = y_test,\n",
    "                                   y_pred = y_test_predicted_labels_tfidf_rfc)\n",
    "df_metrics_compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les métriques sur le modèle RandomForest sont moins bonnes mais semblent cependant plus cohérente avec les données, ce d'autant que les métriques Jaccard et F1 sont proches. D'autre part, nous pouvons vérifier le nombre de lignes dont les Tags ne sont pas prédit afin de voir si l'un des modèles est meilleur :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T13:22:15.782721Z",
     "iopub.status.busy": "2021-07-12T13:22:15.782457Z",
     "iopub.status.idle": "2021-07-12T13:22:15.791083Z",
     "shell.execute_reply": "2021-07-12T13:22:15.790329Z",
     "shell.execute_reply.started": "2021-07-12T13:22:15.782694Z"
    }
   },
   "outputs": [],
   "source": [
    "Tags_per_row_lr = y_test_predicted_labels_tfidf.sum(axis=1)\n",
    "null_rate_lr = round(((Tags_per_row_lr.size - np.count_nonzero(Tags_per_row_lr))\n",
    "                      /Tags_per_row_lr.size)*100,2)\n",
    "Tags_per_row_rfc = y_test_predicted_labels_tfidf_rfc.sum(axis=1)\n",
    "null_rate_rfc = round(((Tags_per_row_rfc.size - np.count_nonzero(Tags_per_row_rfc))\n",
    "                       /Tags_per_row_rfc.size)*100,2)\n",
    "print(\"-\"*50)\n",
    "print(\"Percentage of non tagged question for each model\")\n",
    "print(\"-\" * 50)\n",
    "print(\"Logistic Regression: {}%\".format(null_rate_lr))\n",
    "print(\"Random Forest: {}%\".format(null_rate_rfc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le Random Forest semble donc plus approprié à notre programme d'auto-tagging sur les données Stackoverflow. Nous allons à présent tester ce modèle RandomForest avec Classifier Chains pour remplacer la méthode One versus rest :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modèle RandomForest avec Classifier Chains\n",
    "\n",
    "Avec la méthode ClassifierChains, chaque modèle fait une prédiction dans l'ordre spécifié en utilisant toutes les fonctionnalités disponibles fournies au modèle mais également les prédictions des modèles précédents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T13:22:15.792386Z",
     "iopub.status.busy": "2021-07-12T13:22:15.792137Z",
     "iopub.status.idle": "2021-07-12T13:29:39.978187Z",
     "shell.execute_reply": "2021-07-12T13:29:39.977232Z",
     "shell.execute_reply.started": "2021-07-12T13:22:15.792361Z"
    }
   },
   "outputs": [],
   "source": [
    "rfc_base_model = RandomForestClassifier(**rfc_best_params_ok)\n",
    "chain = ClassifierChain(rfc_base_model, order='random')\n",
    "chain.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T13:29:39.979699Z",
     "iopub.status.busy": "2021-07-12T13:29:39.979434Z",
     "iopub.status.idle": "2021-07-12T13:29:55.407709Z",
     "shell.execute_reply": "2021-07-12T13:29:55.406796Z",
     "shell.execute_reply.started": "2021-07-12T13:29:39.979672Z"
    }
   },
   "outputs": [],
   "source": [
    "# Predict\n",
    "y_test_predicted_labels_tfidf_chain = chain.predict(X_test)\n",
    "\n",
    "# Inverse transform\n",
    "y_test_pred_inversed_chain = multilabel_binarizer\\\n",
    "    .inverse_transform(y_test_predicted_labels_tfidf_chain)\n",
    "\n",
    "print(\"-\"*50)\n",
    "print(\"Print 5 first predicted Tags vs true Tags\")\n",
    "print(\"-\" * 50)\n",
    "print(\"Predicted:\", y_test_pred_inversed_chain[0:5])\n",
    "print(\"True:\", y_test_inversed[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T13:29:55.409074Z",
     "iopub.status.busy": "2021-07-12T13:29:55.408807Z",
     "iopub.status.idle": "2021-07-12T13:29:55.416215Z",
     "shell.execute_reply": "2021-07-12T13:29:55.415308Z",
     "shell.execute_reply.started": "2021-07-12T13:29:55.409045Z"
    }
   },
   "outputs": [],
   "source": [
    "Tags_per_row_chain = y_test_predicted_labels_tfidf_chain.sum(axis=1)\n",
    "null_rate_chain = round(((Tags_per_row_chain.size - np.count_nonzero(Tags_per_row_chain))\n",
    "                       /Tags_per_row_chain.size)*100,2)\n",
    "print(\"-\"*50)\n",
    "print(\"Percentage of non tagged question for chain model\")\n",
    "print(\"-\" * 50)\n",
    "print(\"RandomForest with Classifier Chains: {}%\".format(null_rate_chain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T13:29:55.417693Z",
     "iopub.status.busy": "2021-07-12T13:29:55.417403Z",
     "iopub.status.idle": "2021-07-12T13:29:56.084462Z",
     "shell.execute_reply": "2021-07-12T13:29:56.083613Z",
     "shell.execute_reply.started": "2021-07-12T13:29:55.41766Z"
    }
   },
   "outputs": [],
   "source": [
    "df_metrics_compare = metrics_score(\"RFC Chains\", \n",
    "                                   df=df_metrics_compare,\n",
    "                                   y_true = y_test,\n",
    "                                   y_pred = y_test_predicted_labels_tfidf_chain)\n",
    "df_metrics_compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le modèle RandomForest avec Classifier Chains offre des métriques similaires au modèle avec OneVsRest mais le taux de remplissage des valeurs prédites est encore meilleur.\n",
    "\n",
    "Nous allons à présent tester un dernier modèle d'apprentissage profond avec Keras et un réseau de neurones simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span id=\"section_3_4\">Réseau de neurones avec Keras</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T13:29:56.08573Z",
     "iopub.status.busy": "2021-07-12T13:29:56.08547Z",
     "iopub.status.idle": "2021-07-12T13:29:56.094597Z",
     "shell.execute_reply": "2021-07-12T13:29:56.093775Z",
     "shell.execute_reply.started": "2021-07-12T13:29:56.085704Z"
    }
   },
   "outputs": [],
   "source": [
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "def jaccard_m(y_true, y_pred, smooth=100):\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n",
    "    sum_ = K.sum(K.abs(y_true) + K.abs(y_pred), axis=-1)\n",
    "    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
    "    return (1 - jac) * smooth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons définir une fonction pour constuire le réseau de neurones assez simple. RNN avec une couche cachée et complétement connectée. Nous utiliserons également un Dropout pour éviter le sur-apprentissage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T13:29:56.09591Z",
     "iopub.status.busy": "2021-07-12T13:29:56.095671Z",
     "iopub.status.idle": "2021-07-12T13:29:56.10837Z",
     "shell.execute_reply": "2021-07-12T13:29:56.107644Z",
     "shell.execute_reply.started": "2021-07-12T13:29:56.095887Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_nn(input_dim, hidden_neurons, output_dim):\n",
    "    \"\"\"\n",
    "    Construct a Keras model which will be used to \n",
    "    fit/predict in SKlearn pipeline.\n",
    "    \"\"\"\n",
    "    # Create brain\n",
    "    model = Sequential()\n",
    "    model.add(layers.Dense(hidden_neurons,\n",
    "                           input_dim=input_dim,\n",
    "                           activation='relu'))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.Dense(hidden_neurons,\n",
    "                           input_dim=input_dim,\n",
    "                           activation='relu'))\n",
    "    model.add(layers.Dropout(0.1))\n",
    "    model.add(layers.Dense(output_dim,\n",
    "                           activation='softmax'))\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy', recall_m, precision_m, f1_m, jaccard_m])\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T13:29:56.109673Z",
     "iopub.status.busy": "2021-07-12T13:29:56.109415Z",
     "iopub.status.idle": "2021-07-12T13:29:56.218521Z",
     "shell.execute_reply": "2021-07-12T13:29:56.217803Z",
     "shell.execute_reply.started": "2021-07-12T13:29:56.10965Z"
    }
   },
   "outputs": [],
   "source": [
    "clear_session()\n",
    "\n",
    "model_params = {\n",
    "    'input_dim': X_train.shape[1],\n",
    "    'hidden_neurons': 150,\n",
    "    'output_dim': y_train.shape[1]}\n",
    "\n",
    "keras_model = build_nn(**model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T13:29:56.219616Z",
     "iopub.status.busy": "2021-07-12T13:29:56.219407Z",
     "iopub.status.idle": "2021-07-12T13:30:19.495592Z",
     "shell.execute_reply": "2021-07-12T13:30:19.494874Z",
     "shell.execute_reply.started": "2021-07-12T13:29:56.219596Z"
    }
   },
   "outputs": [],
   "source": [
    "history = keras_model.fit(X_train, y_train,\n",
    "                          epochs=20,\n",
    "                          batch_size=256,\n",
    "                          verbose=0,\n",
    "                          validation_data=(X_test, y_test),\n",
    "                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T13:30:19.496956Z",
     "iopub.status.busy": "2021-07-12T13:30:19.496608Z",
     "iopub.status.idle": "2021-07-12T13:30:20.576023Z",
     "shell.execute_reply": "2021-07-12T13:30:20.575357Z",
     "shell.execute_reply.started": "2021-07-12T13:30:19.49693Z"
    }
   },
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "scores = keras_model.evaluate(X_test, y_test)\n",
    "df_metrics_compare[\"Keras NN\"] = [scores[i] for i in [1,4,5,2,3]]\n",
    "df_metrics_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T13:30:20.577165Z",
     "iopub.status.busy": "2021-07-12T13:30:20.576924Z",
     "iopub.status.idle": "2021-07-12T13:30:20.887974Z",
     "shell.execute_reply": "2021-07-12T13:30:20.887382Z",
     "shell.execute_reply.started": "2021-07-12T13:30:20.577142Z"
    }
   },
   "outputs": [],
   "source": [
    "train_accuracy = history.history.get('accuracy', [])\n",
    "train_f1 = history.history.get('f1_m', [])\n",
    "val_accuracy = history.history.get('val_accuracy', [])\n",
    "val_f1 = history.history.get('val_f1_m', [])\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(25, 8))\n",
    "axes[0].plot(np.arange(0,20,1),\n",
    "             train_accuracy,\n",
    "             label=\"Train\")\n",
    "axes[0].plot(np.arange(0,20,1),\n",
    "             val_accuracy,\n",
    "             linestyle='--', color='g', alpha=.7,\n",
    "             label=\"Validation\")\n",
    "axes[0].set_xticks(np.arange(0,20,5))\n",
    "axes[0].set_xlabel(\"Epochs\")\n",
    "axes[0].set_ylabel(\"Accuracy score\")\n",
    "axes[0].set_title('Model accuracy through epochs',\n",
    "                  color='#f48023', fontweight='bold')\n",
    "axes[0].legend(loc=4)\n",
    "\n",
    "axes[1].plot(np.arange(0,20,1),\n",
    "             train_f1, label=\"Train\")\n",
    "axes[1].plot(np.arange(0,20,1),\n",
    "             val_f1,\n",
    "             linestyle='--', color='g', alpha=.7,\n",
    "             label=\"Validation\")\n",
    "axes[1].set_xticks(np.arange(0,20,5))\n",
    "axes[1].set_xlabel(\"Epochs\")\n",
    "axes[1].set_ylabel(\"F1 score\")\n",
    "axes[1].set_title('Model F1 score through epochs',\n",
    "                  color='#f48023', fontweight='bold')\n",
    "axes[1].legend(loc=4)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T13:30:20.889198Z",
     "iopub.status.busy": "2021-07-12T13:30:20.888856Z",
     "iopub.status.idle": "2021-07-12T13:30:21.645219Z",
     "shell.execute_reply": "2021-07-12T13:30:21.64438Z",
     "shell.execute_reply.started": "2021-07-12T13:30:20.889172Z"
    }
   },
   "outputs": [],
   "source": [
    "# Make prediction with Keras Model\n",
    "y_test_predicted_labels_tfidf_keras = keras_model.predict(X_test)\n",
    "y_test_predicted_labels_tfidf_keras = np.where(y_test_predicted_labels_tfidf_keras >= 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T13:30:21.646866Z",
     "iopub.status.busy": "2021-07-12T13:30:21.646499Z",
     "iopub.status.idle": "2021-07-12T13:30:21.744332Z",
     "shell.execute_reply": "2021-07-12T13:30:21.743504Z",
     "shell.execute_reply.started": "2021-07-12T13:30:21.64683Z"
    }
   },
   "outputs": [],
   "source": [
    "# Inverse transform\n",
    "y_test_pred_inversed_keras = multilabel_binarizer\\\n",
    "    .inverse_transform(y_test_predicted_labels_tfidf_keras)\n",
    "\n",
    "print(\"-\"*50)\n",
    "print(\"Print 5 first predicted Tags vs true Tags\")\n",
    "print(\"-\" * 50)\n",
    "print(\"Predicted:\", y_test_pred_inversed_keras[0:5])\n",
    "print(\"True:\", y_test_inversed[0:5])\n",
    "\n",
    "Tags_per_row_keras = y_test_predicted_labels_tfidf_keras.sum(axis=1)\n",
    "null_rate_keras = round(((Tags_per_row_keras.size - np.count_nonzero(Tags_per_row_keras))\n",
    "                       /Tags_per_row_keras.size)*100,2)\n",
    "print(\"\\n\")\n",
    "print(\"-\"*50)\n",
    "print(\"Percentage of non tagged question for Keras model\")\n",
    "print(\"-\" * 50)\n",
    "print(\"Keras model: {}%\".format(null_rate_keras))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sélection du modèle final\n",
    "\n",
    "Pour sélectionner le modèle final, nous allons nous baser sur les scores obtenus aux métriques Jaccard et F1. Nous prendrons également en compte le taux de \"non prédits\" pour trouver le meilleur compromis entre tout ces indicateurs de performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T13:30:21.745956Z",
     "iopub.status.busy": "2021-07-12T13:30:21.745592Z",
     "iopub.status.idle": "2021-07-12T13:30:22.193959Z",
     "shell.execute_reply": "2021-07-12T13:30:22.193146Z",
     "shell.execute_reply.started": "2021-07-12T13:30:21.74592Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x = np.arange(len(df_metrics_compare.columns))\n",
    "width = 0.35\n",
    "\n",
    "fig = plt.figure(figsize=(18,10))\n",
    "ax1 = fig.add_subplot(111)\n",
    "f1_scores = ax1.bar(x - width/2, df_metrics_compare.iloc[1,:], width, label=\"F1 score\")\n",
    "jacc_scores = ax1.bar(x + width/2, df_metrics_compare.iloc[2,:], width, label=\"Jaccard score\")\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "non_predict = ax2.plot(x, [0,30.08,4.45,1.45,21.88],\n",
    "                       linestyle='--',\n",
    "                       color=\"red\", alpha=.7,\n",
    "                       label='No predict (%)')\n",
    "ax2.grid(None)\n",
    "\n",
    "ax1.set_ylabel('Scores')\n",
    "ax1.set_title('Comparaison des scores par modèles \\n',\n",
    "              color=\"#641E16\", \n",
    "              fontdict={'fontsize': 30})\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(df_metrics_compare.columns)\n",
    "\n",
    "lines, labels = ax1.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "ax1.legend(lines + lines2, labels + labels2, loc=0,\n",
    "           fontsize=15)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export fitted model and Preprocessor\n",
    "joblib.dump(multi_logit_cv,'logit_nlp_model.pkl')\n",
    "joblib.dump(vectorizer,'tfidf_vectorizer.pkl')\n",
    "joblib.dump(multilabel_binarizer,'multilabel_binarizer.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, redirect, url_for, flash, jsonify\n",
    "import numpy as np\n",
    "import pickle as p\n",
    "import json\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "\n",
    "@app.route('/api/', methods=['POST'])\n",
    "def makecalc():\n",
    "    data = request.get_json()\n",
    "    prediction = np.array2string(model.predict(data))\n",
    "\n",
    "    return jsonify(prediction)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    modelfile = 'logit_nlp_model.pkl'\n",
    "    model = joblib.load(open(modelfile, 'rb'))\n",
    "    app.run(debug=True, host='0.0.0.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "url = 'http://0.0.0.0:5000/api/'\n",
    "\n",
    "headers = {'content-type': 'application/json', 'Accept-Charset': 'UTF-8'}\n",
    "r = requests.post(url, data=j_data, headers=headers)\n",
    "print(r, r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "headers = {'Content-type': 'application/json'}\n",
    "response = requests.get('http://0.0.0.0:5000/api/',headers=headers)\n",
    "print(\"-\"*50)\n",
    "print(\"API test response :\")\n",
    "print(\"-\"*50)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
